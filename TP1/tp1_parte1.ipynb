{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ejercicio 1\n",
    "Parte 1 (imágenes en /white_patchy /coord_cromaticas)\n",
    "1) Implementar el algoritmo de pasaje a coordenadas cromáticas para librarnos de las variaciones de contraste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar las imágenes \n",
    "imagen_original_1 = cv2.imread('coord_cromaticas/CoordCrom_1.png')\n",
    "\n",
    "imagen_original_2 = cv2.imread('coord_cromaticas/CoordCrom_2.png')\n",
    "\n",
    "imagen_original_3 = cv2.imread('coord_cromaticas/CoordCrom_3.png')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# función para pasaje a coordenadas cromáticas\n",
    "def coord_cromatica (imagen):\n",
    "   \n",
    "    imagen_rgb = cv2.cvtColor(imagen, cv2.COLOR_BGR2RGB)\n",
    "  \n",
    "    \n",
    "    # Separa los canales R, G, B\n",
    "    R = imagen_rgb[:, :, 0].astype(float)\n",
    "    G = imagen_rgb[:, :, 1].astype(float)\n",
    "    B = imagen_rgb[:, :, 2].astype(float)\n",
    "    \n",
    "    # Calcula la suma de los canales\n",
    "    suma = R + G + B   \n",
    "    # Inicializa r, g, b con ceros\n",
    "    r = np.zeros_like(R)\n",
    "    g = np.zeros_like(G)\n",
    "    b = np.zeros_like(B)  \n",
    "\n",
    "    # Calcula las coordenadas cromaticas donde la suma no es cero\n",
    "    # Usa una mascara para evitar la division por cero\n",
    "    mascara = suma > 0\n",
    "    r[mascara] = R[mascara] / suma[mascara]\n",
    "    g[mascara] = G[mascara] / suma[mascara]\n",
    "    b[mascara] = B[mascara] / suma[mascara]\n",
    "\n",
    "    # Crea la imagen en coordenadas cromaticas\n",
    "    imagen_cromatica = np.stack([r, g, b], axis=-1)\n",
    "\n",
    "    return imagen_rgb, imagen_cromatica \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mostrar_coor_crom(imagen_rgb, imagen_cromatica):\n",
    "  \n",
    "    # Muestra la imagen original y la imagen en coordenadas cromaticas\n",
    "    plt.figure(figsize=(12, 6))\n",
    "\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.title(\"Imagen Original\")\n",
    "    plt.imshow(imagen_rgb)\n",
    "    plt.axis('off')\n",
    "\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.title(\"Imagen en Coordenadas Cromáticas\")\n",
    "    plt.imshow(imagen_cromatica)\n",
    "    plt.axis('off')\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "imagen_rgb, imagen_cromatica = coord_cromatica(imagen_original_1)\n",
    "mostrar_coor_crom(imagen_rgb, imagen_cromatica)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imagen_rgb, imagen_cromatica = coord_cromatica(imagen_original_2)\n",
    "mostrar_coor_crom(imagen_rgb, imagen_cromatica)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imagen_rgb, imagen_cromatica = coord_cromatica(imagen_original_3)\n",
    "mostrar_coor_crom(imagen_rgb, imagen_cromatica)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Implementar el algoritmo White Patch para librarnos de las diferencias de color de iluminación."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "\n",
    "# Carga de la carpet que contiene las imágenes png\n",
    "folder_path = './white_patch/*.png'  \n",
    "\n",
    "# Lista para almacenar las imágenes\n",
    "images = []\n",
    "\n",
    "# Usar glob para encontrar las imágenes con el path relativo\n",
    "for img_path in glob.glob(folder_path):\n",
    "    # Cargar la imagen\n",
    "    img = cv2.imread(img_path)\n",
    "    # Verificar si la imagen se cargó correctamente\n",
    "    if img is not None:\n",
    "        images.append(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def white_patch(imagen):\n",
    "   \n",
    "    # Convierte la imagen de BGR (por defecto en OpenCV) a RGB\n",
    "    imagen_rgb = cv2.cvtColor(imagen, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    # Separa los canales R, G, B\n",
    "    R = imagen_rgb[:, :, 0].astype(float)\n",
    "    G = imagen_rgb[:, :, 1].astype(float)\n",
    "    B = imagen_rgb[:, :, 2].astype(float)\n",
    "\n",
    "    # Encuentra los valores maximos de cada canal\n",
    "    max_R = np.max(R)\n",
    "    max_G = np.max(G)\n",
    "    max_B = np.max(B)\n",
    "\n",
    "    # Calcula los factores de correccion\n",
    "    escala_R = 255.0 / max_R\n",
    "    escala_G = 255.0 / max_G\n",
    "    escala_B = 255.0 / max_B \n",
    "\n",
    "    # Aplica los factores de correccion\n",
    "    R = np.clip(R * escala_R, 0, 255).astype(np.uint8)\n",
    "    G = np.clip(G * escala_G, 0, 255).astype(np.uint8)\n",
    "    B = np.clip(B * escala_B, 0, 255).astype(np.uint8)\n",
    "\n",
    "    # Recombina los canales\n",
    "    imagen_balanceada = cv2.merge([R, G, B])\n",
    "\n",
    "    return imagen_rgb, imagen_balanceada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mostrar_white_patch(imagen_rgb, imagen_balanceada):\n",
    "   \n",
    "    # Muestra la imagen original y la imagen con white patch\n",
    "    plt.figure(figsize=(12, 6))\n",
    "\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.title(\"Imagen Original\")\n",
    "    plt.imshow(imagen_rgb)\n",
    "    plt.axis('off')\n",
    "\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.title(\"Imagen con White Patch\")\n",
    "    plt.imshow(imagen_balanceada)\n",
    "    plt.axis('off')\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mostrar las imágenes\n",
    "for idx, img in enumerate(images):\n",
    "    rgb,balanceada = white_patch(img)\n",
    "    mostrar_white_patch(rgb,balanceada)\n",
    "   \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "\n",
    "# Carga de la carpet que contiene las imágenes jpg\n",
    "folder_path = './white_patch/*.jpg'  \n",
    "\n",
    "# Lista para almacenar las imágenes\n",
    "images = []\n",
    "\n",
    "# Usar glob para encontrar las imágenes con el path relativo\n",
    "for img_path in glob.glob(folder_path):\n",
    "    # Cargar la imagen\n",
    "    img = cv2.imread(img_path)\n",
    "    # Verificar si la imagen se cargó correctamente\n",
    "    if img is not None:\n",
    "        images.append(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mostrar las imágenes\n",
    "for idx, img in enumerate(images):\n",
    "    rgb,balanceada = white_patch(img)\n",
    "    mostrar_white_patch(rgb,balanceada)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Mostrar los resultados obtenidos y analizar las posibles fallas (si es que las hay) en el caso de White patch.\n",
    "\n",
    "\n",
    "Imagen de las cuatro manos: \n",
    "\n",
    "    El algoritmo logra su objetivo, ajustando los colores para que los objetos blancos se vean realmente blancos. Esto se basa en encontrar un píxel cercano al blanco puro (máximos valores RGB) y usarlo para ajustar el resto de la imagen. En este caso, la pared blanca de fondo permite que el algoritmo funcione correctamente.\n",
    "\n",
    "Imagen del Depredador: \n",
    "\n",
    "    El algoritmo funciona mejor en la imagen con luz roja, probablemente porque identifica más fácilmente un valor máximo en el canal rojo y ajusta el balance de blancos en consecuencia. Además, el ojo humano percibe mejor el rojo y verde que el azul, por lo que la corrección bajo luz roja parece más natural. La diferencia en los resultados entre formatos PNG y JPG se debe a que el JPG usa compresión con pérdida, lo que afecta los colores, mientras que el PNG mantiene los datos originales, permitiendo una corrección más precisa."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
